{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import pytrec_eval\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# [Evaluator class remains unchanged]\n",
    "class Evaluator:\n",
    "    @staticmethod\n",
    "    def evaluate(\n",
    "        qrels: dict[str, dict[str, int]],\n",
    "        results: dict[str, dict[str, float]],\n",
    "        k_values: list[int],\n",
    "        ignore_identical_ids: bool = True,\n",
    "    ) -> tuple[dict[str, float], dict[str, float], dict[str, float], dict[str, float]]:\n",
    "        if ignore_identical_ids:\n",
    "            logger.info(\n",
    "                \"For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to not ignore them.\"\n",
    "            )\n",
    "            for qid, rels in results.items():\n",
    "                for pid in list(rels):\n",
    "                    if qid == pid:\n",
    "                        results[qid].pop(pid)\n",
    "\n",
    "        ndcg = {}\n",
    "        _map = {}\n",
    "        recall = {}\n",
    "        precision = {}\n",
    "\n",
    "        for k in k_values:\n",
    "            ndcg[f\"NDCG@{k}\"] = 0.0\n",
    "            _map[f\"MAP@{k}\"] = 0.0\n",
    "            recall[f\"Recall@{k}\"] = 0.0\n",
    "            precision[f\"P@{k}\"] = 0.0\n",
    "\n",
    "        map_string = \"map_cut.\" + \",\".join([str(k) for k in k_values])\n",
    "        ndcg_string = \"ndcg_cut.\" + \",\".join([str(k) for k in k_values])\n",
    "        recall_string = \"recall.\" + \",\".join([str(k) for k in k_values])\n",
    "        precision_string = \"P.\" + \",\".join([str(k) for k in k_values])\n",
    "        evaluator = pytrec_eval.RelevanceEvaluator(\n",
    "            qrels, {map_string, ndcg_string, recall_string, precision_string}\n",
    "        )\n",
    "        scores = evaluator.evaluate(results)\n",
    "\n",
    "        for query_id in scores.keys():\n",
    "            for k in k_values:\n",
    "                ndcg[f\"NDCG@{k}\"] += scores[query_id].get(\"ndcg_cut_\" + str(k), 0)\n",
    "                _map[f\"MAP@{k}\"] += scores[query_id].get(\"map_cut_\" + str(k), 0)\n",
    "                recall[f\"Recall@{k}\"] += scores[query_id].get(\"recall_\" + str(k), 0)\n",
    "                precision[f\"P@{k}\"] += scores[query_id].get(\"P_\" + str(k), 0)\n",
    "\n",
    "        num_queries = len(scores)\n",
    "        for k in k_values:\n",
    "            ndcg[f\"NDCG@{k}\"] = round(ndcg[f\"NDCG@{k}\"] / num_queries, 5)\n",
    "            _map[f\"MAP@{k}\"] = round(_map[f\"MAP@{k}\"] / num_queries, 5)\n",
    "            recall[f\"Recall@{k}\"] = round(recall[f\"Recall@{k}\"] / num_queries, 5)\n",
    "            precision[f\"P@{k}\"] = round(precision[f\"P@{k}\"] / num_queries, 5)\n",
    "\n",
    "        for metric in [ndcg, _map, recall, precision]:\n",
    "            logger.info(\"\\nEvaluation metrics:\")\n",
    "            for key in metric.keys():\n",
    "                logger.info(f\"{key}: {metric[key]:.4f}\")\n",
    "\n",
    "        return ndcg, _map, recall, precision\n",
    "\n",
    "# --------------------------\n",
    "# Retrieval and Evaluation\n",
    "# --------------------------\n",
    "def get_embedding(texts):\n",
    "    return model.encode(texts, convert_to_numpy=True, device=device)\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Process the MIRACL dev split to create queries, qrels, and corpus from the same data.\n",
    "    \"\"\"\n",
    "    data = dataset[\"dev\"]\n",
    "    \n",
    "    # Create queries dictionary: {query_id: query_text}\n",
    "    queries = {str(item[\"query_id\"]): item[\"query\"] for item in data}\n",
    "    \n",
    "    # Create qrels dictionary: {query_id: {passage_id: relevance}}\n",
    "    # and corpus dictionary: {passage_id: passage_text}\n",
    "    qrels = {}\n",
    "    corpus = {}\n",
    "    for item in data:\n",
    "        query_id = str(item[\"query_id\"])\n",
    "        qrels[query_id] = {}\n",
    "        # Positive passages\n",
    "        for passage in item[\"positive_passages\"]:\n",
    "            passage_id = str(passage[\"docid\"])\n",
    "            qrels[query_id][passage_id] = 1\n",
    "        # Negative passages\n",
    "        for passage in item[\"negative_passages\"]:\n",
    "            passage_id = str(passage[\"docid\"])\n",
    "            qrels[query_id][passage_id] = 0\n",
    "    \n",
    "    # Load corpus from miracl/miracl-corpus for Yoruba\n",
    "    corpus_dataset = load_dataset(\"miracl/miracl-corpus\", \"yo\", trust_remote_code=True)[\"train\"]\n",
    "    corpus = {str(item[\"docid\"]): item[\"text\"] for item in corpus_dataset}\n",
    "    \n",
    "    return queries, qrels, corpus\n",
    "\n",
    "def build_faiss_index(corpus_embeddings, corpus_ids):\n",
    "    \"\"\"\n",
    "    Index document embeddings using FAISS for efficient search, storing corpus_ids for later use.\n",
    "    \"\"\"\n",
    "    dim = corpus_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(corpus_embeddings)\n",
    "    return index, corpus_ids  # Return both index and corpus_ids\n",
    "\n",
    "def evaluate_retrieval(dataset, lang):\n",
    "    print(f\"\\nEvaluating language: {lang}...\")\n",
    "    \n",
    "    # Preprocess dataset\n",
    "    queries, qrels, corpus_dict = preprocess_dataset(dataset)\n",
    "    if not queries or not corpus_dict:\n",
    "        print(f\"No valid data found for {lang}\")\n",
    "        return 0, 0\n",
    "\n",
    "    # Convert to lists for embedding while maintaining ID mappings\n",
    "    query_ids = list(queries.keys())\n",
    "    query_texts = list(queries.values())\n",
    "    corpus_ids = list(corpus_dict.keys())\n",
    "    corpus_texts = list(corpus_dict.values())\n",
    "\n",
    "    # Generate embeddings\n",
    "    query_embeddings = model.encode(query_texts, convert_to_numpy=True, device=device)\n",
    "    corpus_embeddings = model.encode(corpus_texts, convert_to_numpy=True, device=device)\n",
    "    # Build FAISS index\n",
    "    index, retrieved_corpus_ids = build_faiss_index(corpus_embeddings, corpus_ids)\n",
    "    \n",
    "    # Search\n",
    "    max_k = max(10, 100)\n",
    "    distances, indices = index.search(query_embeddings, max_k)\n",
    "    \n",
    "    # Format results: {query_id: {passage_id: score}}\n",
    "    results = {}\n",
    "    for i, qid in enumerate(query_ids):\n",
    "        results[qid] = {\n",
    "            corpus_ids[idx]: float(-distances[i][j])  # Negative distance as score\n",
    "            for j, idx in enumerate(indices[i][:max_k])\n",
    "        }\n",
    "    \n",
    "    # Evaluate\n",
    "    k_values = [10, 100]\n",
    "    ndcg, _map, recall, precision = Evaluator.evaluate(qrels, results, k_values)\n",
    "    \n",
    "    ndcg_at_10 = ndcg.get(\"NDCG@10\", 0)\n",
    "    recall_at_100 = recall.get(\"Recall@100\", 0)\n",
    "    print(f\"\\n{lang} - NDCG@10: {ndcg_at_10:.4f}, Recall@100: {recall_at_100:.4f}\")\n",
    "    \n",
    "    return recall_at_100, ndcg_at_10\n",
    "\n",
    "# --------------------------\n",
    "# Main Code\n",
    "# --------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model_name = \"facebook/mcontriever-msmarco\"\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "# Load MIRACL dataset (dev split only)\n",
    "dataset_name = \"miracl/miracl\"\n",
    "dataset = load_dataset(dataset_name, \"yo\", trust_remote_code=True)\n",
    "lang = \"Yoruba (yo)\"\n",
    "\n",
    "# Run evaluation\n",
    "recall, ndcg = evaluate_retrieval(dataset, lang)\n",
    "print(f\"\\nFinal Results:\\nRecall@100: {recall:.4f}\\nNDCG@10: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strictly follow the structure of the image\n",
    "(stardard one: 0.415 nDCG@10 and 0.770 Recall@100)\n",
    "\n",
    "model:\"facebook/mcontriever-msmarco\"\n",
    "\n",
    "dataset&datasetcorpus: miracl/miracl&miracl/miracl-corpus\n",
    "\n",
    "Result:\n",
    "Recall@100: 0.2661\n",
    "NDCG@10: 0.0655\n",
    "\n",
    "\n",
    "\n",
    "change the FAISS index using cousine similarity, code as below:\n",
    "\n",
    "\n",
    "```def build_faiss_index(corpus_embeddings, corpus_ids):\n",
    "    \"\"\"\n",
    "    Index document embeddings using FAISS for efficient search, storing corpus_ids for later use.\n",
    "    \"\"\"\n",
    "    dim = corpus_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)  # inner product (after normalization equals cosine similarity)\n",
    "    faiss.normalize_L2(corpus_embeddings)\n",
    "    index.add(corpus_embeddings)\n",
    "    return index, corpus_ids  # Return both index and corpus_ids\n",
    "```\n",
    "Result:\n",
    "Recall@100: 0.3950\n",
    "NDCG@10: 0.1517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Retrieval and Evaluation\n",
    "# --------------------------\n",
    "def preprocess_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Process the MIRACL dev split to create queries, qrels, and load corpus from miracl/miracl-corpus.\n",
    "    \"\"\"\n",
    "    data = dataset[\"dev\"]\n",
    "    \n",
    "    # Create queries dictionary: {query_id: query_text}\n",
    "    queries = {str(item[\"query_id\"]): item[\"query\"] for item in data}\n",
    "    \n",
    "    # Create qrels dictionary: {query_id: {passage_id: relevance}}\n",
    "    qrels = {}\n",
    "\n",
    "    for item in data:\n",
    "        query_id = str(item[\"query_id\"])\n",
    "        qrels[query_id] = {}\n",
    "        # Positive passages\n",
    "        for passage in item[\"positive_passages\"]:\n",
    "            passage_id = str(passage[\"docid\"])\n",
    "            qrels[query_id][passage_id] = 1\n",
    "\n",
    "        # Negative passages\n",
    "        for passage in item[\"negative_passages\"]:\n",
    "            passage_id = str(passage[\"docid\"])\n",
    "            qrels[query_id][passage_id] = 0\n",
    "\n",
    "    \n",
    "    # Load and filter corpus from miracl/miracl-corpus for Yoruba, keeping only relevant documents\n",
    "    corpus_dataset = load_dataset(\"miracl/miracl-corpus\", \"yo\", trust_remote_code=True)[\"train\"]\n",
    "    corpus = {str(item[\"docid\"]): item[\"text\"] for item in corpus_dataset if str(item[\"docid\"])}\n",
    "    \n",
    "    return queries, qrels, corpus\n",
    "\n",
    "def build_faiss_index(corpus_embeddings, corpus_ids):\n",
    "    \"\"\"\n",
    "    Index document embeddings using FAISS for efficient search, storing corpus_ids for later use.\n",
    "    \"\"\"\n",
    "    dim = corpus_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(corpus_embeddings)\n",
    "    return index, corpus_ids  # Return both index and corpus_ids\n",
    "\n",
    "# --------------------------\n",
    "# Main Code\n",
    "# --------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model_name = \"nthakur/contriever-base-msmarco\"\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "# Load MIRACL dataset (dev split only)\n",
    "dataset_name = \"miracl/miracl\"\n",
    "dataset = load_dataset(dataset_name, \"yo\", trust_remote_code=True)\n",
    "lang = \"Yoruba (yo)\"\n",
    "\n",
    "# Run evaluation\n",
    "recall, ndcg = evaluate_retrieval(dataset, lang)\n",
    "print(f\"\\nFinal Results:\\nRecall@100: {recall:.4f}\\nNDCG@10: {ndcg:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change the model from facebook/mcontriever-msmarco to nthakur/contriever-base-msmarco\n",
    "FAISS index using L2 distance\n",
    "\n",
    "Recall@100: 0.4181\n",
    "NDCG@10: 0.2161\n",
    "\n",
    "change the FAISS index using cousine similarity, code as below:\n",
    "\n",
    "\n",
    "```def build_faiss_index(corpus_embeddings, corpus_ids):\n",
    "    \"\"\"\n",
    "    Index document embeddings using FAISS for efficient search, storing corpus_ids for later use.\n",
    "    \"\"\"\n",
    "    dim = corpus_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)  # inner product (after normalization equals cosine similarity)\n",
    "    faiss.normalize_L2(corpus_embeddings)\n",
    "    index.add(corpus_embeddings)\n",
    "    return index, corpus_ids  # Return both index and corpus_ids\n",
    "```\n",
    "and change sorces from negative to positive\n",
    "Result:\n",
    "Recall@100: 0.5168\n",
    "NDCG@10: 0.2514"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
