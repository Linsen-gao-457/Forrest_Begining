{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import pytrec_eval\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "def get_embedding(texts):\n",
    "    \"\"\"\n",
    "    Function to generate embeddings\n",
    "    \"\"\"\n",
    "    return model.encode(texts, convert_to_numpy=True, device=device)\n",
    "\n",
    "def preprocess_dataset(dataset, num_queries=200):\n",
    "    \"\"\"\n",
    "    Extracts queries, query IDs, and corpus from the dataset.\n",
    "    \"\"\"\n",
    "    queries = dataset[\"query\"][:num_queries]\n",
    "    query_ids = dataset[\"query_id\"][:num_queries]\n",
    "    \n",
    "    all_positive_passages = [p[0] if p else None for p in dataset[\"positive_passages\"]]\n",
    "    all_negative_passages = [n[0] if n else None for n in dataset[\"negative_passages\"]]\n",
    "    \n",
    "    corpus = list(set(all_positive_passages + all_negative_passages))  # Remove duplicates\n",
    "    corpus = [p for p in corpus if p is not None]  # Remove None values\n",
    "    \n",
    "    query_to_positive = {\n",
    "        qid: set(p) for qid, p in zip(query_ids, dataset[\"positive_passages\"]) if p\n",
    "    }\n",
    "    \n",
    "    return queries, query_ids, corpus, query_to_positive\n",
    "\n",
    "def build_faiss_index(corpus_embeddings):\n",
    "    \"\"\"\n",
    "    Builds a FAISS index for efficient retrieval.\n",
    "    \"\"\"\n",
    "    dim = corpus_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(corpus_embeddings)\n",
    "    return index\n",
    "\n",
    "def evaluate_retrieval(dataset, lang, k_recall=100, k_ndcg=10, num_queries=200):\n",
    "    \"\"\"\n",
    "    Standardized function for evaluating retrieval models on a dataset using pytrec_eval.\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating language: {lang}...\")\n",
    "    \n",
    "    # Preprocess dataset\n",
    "    queries, query_ids, corpus, query_to_positive = preprocess_dataset(dataset, num_queries)\n",
    "    \n",
    "    if not queries or not corpus:\n",
    "        print(f\"No valid data found for {lang}\")\n",
    "        return 0, 0\n",
    "    \n",
    "    # Embed queries and corpus\n",
    "    query_embeddings = get_embedding(queries)\n",
    "    corpus_embeddings = get_embedding(corpus)\n",
    "    \n",
    "    # Build FAISS index\n",
    "    index = build_faiss_index(corpus_embeddings)\n",
    "    \n",
    "    # Retrieve top-k results\n",
    "    D, I = index.search(query_embeddings, max(k_recall, k_ndcg))\n",
    "    \n",
    "    # Format results for evaluation\n",
    "    results = {}\n",
    "    for i, qid in enumerate(query_ids):\n",
    "        results[qid] = {corpus[idx]: float(-D[i][j]) for j, idx in enumerate(I[i][:max(k_recall, k_ndcg)])}\n",
    "    \n",
    "    # Format qrels for evaluation\n",
    "    qrels = {qid: {doc: 1 for doc in query_to_positive.get(qid, [])} for qid in query_ids}\n",
    "    \n",
    "    # Use pytrec_eval to compute Recall@100 and NDCG@10\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(qrels, {f\"recall.{k_recall}\", f\"ndcg_cut.{k_ndcg}\"})\n",
    "    scores = evaluator.evaluate(results)\n",
    "    \n",
    "    recall_100 = np.mean([scores[qid].get(f\"recall_{k_recall}\", 0) for qid in query_ids])\n",
    "    ndcg_10 = np.mean([scores[qid].get(f\"ndcg_cut_{k_ndcg}\", 0) for qid in query_ids])\n",
    "    \n",
    "    print(f\"{lang} - Recall@100: {recall_100:.4f}, NDCG@10: {ndcg_10:.4f}\")\n",
    "    return recall_100, ndcg_10\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"HIT-TMG/KaLM-embedding-multilingual-mini-v1\"\n",
    "model = SentenceTransformer(model_name).to(device)\n",
    "\n",
    "# Define the   languages to evaluate\n",
    "languages = [\"ar\", \"bn\", \"en\", \"es\", \"fa\", \"fi\", \"fr\", \"hi\", \"id\", \"ja\", \"ko\", \"ru\", \"sw\", \"te\", \"th\", \"zh\"]\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "# Iterate over each language and evaluate\n",
    "for lang in languages:\n",
    "    print(f\"\\nProcessing language: {lang}\")\n",
    "    dataset = load_dataset(\"miracl/miracl\", lang, split=\"dev\")  # Load dataset\n",
    "    recall, ndcg = evaluate_retrieval(dataset)  # Evaluate\n",
    "    results[lang] = {\"Recall@100\": recall, \"NDCG@10\": ndcg}\n",
    "\n",
    "# Load mContriever model from Hugging Face\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"facebook/mcontriever-msmarco\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)\n",
    "dataset_name = \"miracl/miracl-corpus\"\n",
    "dataset = load_dataset(dataset_name, \"yo\")  # \"yo\" for Yoruba language\n",
    "lang = \"Yoruba (yo)\"\n",
    "evaluate_retrieval(dataset, lang)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
